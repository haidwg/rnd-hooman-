{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2uHiFBUAGlm"
      },
      "source": [
        "#Artificial Intelligence - COMP9414\n",
        "###Tutorial week 1 - Rule-based Systems\n",
        "\n",
        "@Author: __Francisco Cruz__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vQYoNXyEtvZ"
      },
      "source": [
        "##Rule-based Systems\n",
        "\n",
        "A rule-based system is a type of computer system that leverages domain-specific knowledge in the form of predefined rules.\n",
        "In any field or domain, there exists a body of specialised knowledge that experts use to solve problems or make decisions. This knowledge encompasses facts, relationships, constraints, and patterns relevant to that domain.\n",
        "In a rule-based system, this domain-specific knowledge is captured and represented in the form of rules.\n",
        "For example, in the medical domain, knowledge about symptoms, diseases, and their relationships might be represented.\n",
        "\n",
        "Rules form the backbone of a rule-based system.\n",
        "These rules are expressed in the form of \"if-then\" statements, also known as production rules.\n",
        "Each rule consists of two parts: the antecedent (the \"if\" part) and the consequent (the \"then\" part).\n",
        "The antecedent specifies the conditions or criteria that must be met for the rule to be applied, while the consequent specifies the action or conclusion to be taken if the conditions are met.\n",
        "Rules encode the logical relationships, decision criteria, or problem-solving strategies relevant to the domain.\n",
        "\n",
        "Rule-based systems can effectively solve problems, make decisions, or provide recommendations within their designated domain.\n",
        "These systems are particularly useful in domains where expertise can be codified into explicit rules, such as expert systems, diagnostic systems, decision support systems, and natural language processing applications.\n",
        "For instance, a rule-based system might assist a doctor in choosing a diagnosis based on symptoms, or select tactical moves to play a game.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mountain Car Environment\n",
        "\n",
        "For this tutorial, we will use the gymnasium library.\n",
        "This is a well-known library regularly used for reinforcement learning environments.\n",
        "In particular, we will use the Mountain Car environment and create a simple rule-based system to control the car movement.\n",
        "\n",
        "The Mountain Car is a control problem in which a car is located on a unidimensional track between two steep hills.\n",
        "The car starts at a random position at the bottom of the valley ($-0.6 < x < 0.4$) with no velocity ($v = 0$).\n",
        "The aim is to reach the top of the right hill.\n",
        "However, the car engine does not have enough power to claim to the top directly and, therefore, needs to build momentum moving toward the left hill first.\n",
        "An agent controlling the car movements observes two state variables, namely, the position $x$ and the velocity $v$.\n",
        "The position $x$ varies between $-1.2$ and $0.6$ in the x-axis (with $x=-0.53$ the lowest height) and the velocity $v$ between -0.07 and 0.07.\n",
        "The agent can take three different actions: accelerate the car to the left (0), do not accelerate (1), and accelerate the car to the right (2).\n",
        "The task is completed in case the top of the right hill is climbed ($x \\geq 0.5$) or if the length of the episode is 200 iterations in which case the episode is forcibly terminated.\n",
        "\n",
        "Gymnasium environments provide access to the environment action and observation spaces.\n",
        "The following code initialises an environment while visually rendering the output (be aware that rendering the output might not be available on platforms such as Colab).\n",
        "Next, a random action is selected and performed in the environment for a predetermined number of iterations.\n",
        "\n",
        "\n",
        ">import gymnasium as gym\n",
        "\n",
        ">env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
        "\n",
        ">observation, info = env.reset()\n",
        "\n",
        ">for _ in range(1000):\n",
        "\n",
        ">>    action = env.action_space.sample()\n",
        "\n",
        ">>    observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        ">>    if terminated or truncated:\n",
        "\n",
        ">>>    observation, info = env.reset()\n",
        "\n",
        ">env.close()\n"
      ],
      "metadata": {
        "id": "dWpl_vTazzzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Section 2.1.__ Using Python, create the Mountain Car environment using Gymnasium, then start resetting the environment. Gymnasium needs swig and box2d packages, therefore, before creating the environment you should run the following:."
      ],
      "metadata": {
        "id": "8-v2Zsu7125c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig\n",
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rHWaJoxw0ZO",
        "outputId": "afb7c74b-29ec-4887-aecc-8880fe8fdf14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.2.1\n",
            "Collecting gymnasium[box2d]\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium[box2d])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2376134 sha256=536cbb1b29d016f25e91b4c9d9ca493f8b5183d99c38aa4e45891041de4b30b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: farama-notifications, box2d-py, gymnasium\n",
            "Successfully installed box2d-py-2.3.5 farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "observation, info = env.reset()\n",
        "print(\"Starting Mountain Car environment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl9WExKkkd0Y",
        "outputId": "2c2fa4af-ba6e-4578-ab60-c9ec29be69a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Mountain Car environment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Section 2.2.__ Create a loop with an adequate number of iterations to run the simulation."
      ],
      "metadata": {
        "id": "OkLDdvrVlxdY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Section 2.3.__ Select a random action and execute it in the environment. Observe how the car position varies over time."
      ],
      "metadata": {
        "id": "0FEu6-KJmFxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Section 2.2\n",
        "for i in range(200):\n",
        "    #Section 2.3\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    #print(observation) #if visual rendering not available\n",
        "\n",
        "    if terminated or truncated:\n",
        "        observation, info = env.reset()\n",
        "        break\n",
        "\n",
        "print(\"Finished in %i steps\"%i)\n",
        "env.close()"
      ],
      "metadata": {
        "id": "WiHdMrKk10t-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a540847-8a87-47f6-c953-3fa53fcd881c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 199 steps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Section 3.1.__ Instead of selecting a random action, select accelerating the car to the right at each time step."
      ],
      "metadata": {
        "id": "mK9sEVj7oGfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200):\n",
        "    action = 2\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    #print(observation) #if visual rendering not available\n",
        "\n",
        "    if terminated or truncated:\n",
        "        observation, info = env.reset()\n",
        "        break\n",
        "\n",
        "print(\"Finished in %i steps\"%i)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O4mRjJLoY39",
        "outputId": "3679307f-f5dd-48e7-f11c-c3794c678977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 199 episodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the car needs to build momentum, let's create two simple rules as follows:\n",
        "\n",
        "* Accelerate the car to the right if it is climbing the hill to the right while increasing the velocity.\n",
        "* Accelerate the car to the left if it is climbing the hill to the left while decreasing the velocity."
      ],
      "metadata": {
        "id": "F15lGkg0oxJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200):\n",
        "    if observation[0] > -0.53 and observation[1] > 0:\n",
        "      action = 2\n",
        "    elif observation[0] < -0.53 and observation[1] < 0:\n",
        "      action = 0\n",
        "    else:\n",
        "      action = 1 #or maybe a random action\n",
        "\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    #print(observation) #if visual rendering not available\n",
        "\n",
        "    if terminated or truncated:\n",
        "        observation, info = env.reset()\n",
        "        break\n",
        "\n",
        "print(\"Finished in %i steps\"%i)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSAGbO30o-my",
        "outputId": "20c656bd-44ce-4671-c666-5c31e7758707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 160 episodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Section 3.3.__ Let's expand our knowledge base by adding two more rules, as follows:\n",
        "\n",
        "* Accelerate the car to the right if it is climbing the hill to the right while increasing the velocity.\n",
        "* Accelerate the car to the left if it is climbing the hill to the left while decreasing the velocity.\n",
        "* Accelerate the car to the right if it is descending the hill to the left while increasing the velocity.\n",
        "* Accelerate the car to the left if it is descending the hill to the right while decreasing the velocity."
      ],
      "metadata": {
        "id": "E_RcoP0Qp7AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(200):\n",
        "    if observation[0] > -0.53 and observation[1] > 0:\n",
        "      action = 2\n",
        "    elif observation[0] < -0.53 and observation[1] < 0:\n",
        "      action = 0\n",
        "    elif observation[0] < -0.53 and observation[1] > 0:\n",
        "      action = 2\n",
        "    elif observation[0] > -0.53 and observation[1] < 0:\n",
        "      action = 0\n",
        "    else:\n",
        "      action = 1 #or maybe a random action\n",
        "\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    #print(observation) #if visual rendering not available\n",
        "\n",
        "    if terminated or truncated:\n",
        "        observation, info = env.reset()\n",
        "        break\n",
        "\n",
        "print(\"Finished in %i steps\"%i)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-8V1fyasqy6",
        "outputId": "5fe8043d-a7f1-433c-801c-fbff08ae8b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 85 episodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Section 3.4.__ For the previous setups, i.e., always accelerating to the right, two rules knowledge base, and four rules knowledge base, run the experiment 100 times and show the results using boxplots."
      ],
      "metadata": {
        "id": "MSdKz-IVtQ1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#See tutorial1.py code in Moodle"
      ],
      "metadata": {
        "id": "Cdmh6CVFxml3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}